{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":258315,"sourceType":"datasetVersion","datasetId":108201}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\n# Define the path to the clinical readings and mask image folders\nclinical_folder = \"/kaggle/input/chest-xray-masks-and-labels/Lung Segmentation/ClinicalReadings/\"\nmask_folder = \"/kaggle/input/chest-xray-masks-and-labels/Lung Segmentation/masks/\"\n# Create lists to store data and labels\ndata = []\nlabels = []\n\n# Iterate through clinical reading files\nfor clinical_file in os.listdir(clinical_folder):\n    if clinical_file.endswith(\".txt\") and not clinical_file.startswith(\"MCUCXR\"):\n        file_name = os.path.splitext(clinical_file)[0]\n\n        # Read the clinical data from the file\n        with open(os.path.join(clinical_folder, clinical_file), \"r\") as file:\n            lines = [line.strip() for line in file.readlines() if line.strip()]  # Remove empty lines\n            \n            if len(lines) < 2:\n                print(f\"Skipping file with insufficient data: {clinical_file}\")\n                continue  # Skip this data point if there is insufficient data\n\n            # Remove spaces and \"yrs\" from the text line\n            text_line = lines[0].replace(\" \", \"\").replace(\"yrs\", \"\").replace(\",\", \"\")\n            lines[1]= lines[1].replace(\" \", \"\").replace(\"yrs\", \"\").replace(\",\", \"\")\n\n            \n            # Extract gender, age, and disease description based on the first character\n            disease_description = lines[1]\n\n            # Load the corresponding mask image\n            mask_file = os.path.join(mask_folder, f\"{file_name}_mask.png\")\n            \n            # Check if the mask image file exists\n            if not os.path.isfile(mask_file):\n                #print(f\"Mask image not found for: {clinical_file}\")\n                continue\n            \n            # Read the mask image\n            mask_image = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n            mask_image = cv2.resize(mask_image, (224, 224))\n            mask_image = mask_image / 255.0\n            \n            label = 0  # Initialize as 0 (normal)\n            if \"normal\" not in disease_description:\n                label = 1  # Set to 1 if disease is mentioned\n                \n            data.append(mask_image)\n            labels.append(label)\n            \n    if clinical_file.endswith(\".txt\") and clinical_file.startswith(\"MCUCXR\"):\n        file_name = os.path.splitext(clinical_file)[0]\n        # Read the clinical data from the file\n        with open(os.path.join(clinical_folder, clinical_file), \"r\") as file:\n            lines = [line.strip() for line in file.readlines() if line.strip()]  # Remove empty lines\n\n            # Extract gender, age, and disease description based on the first character\n            disease_description = lines[2]\n            # Load the corresponding mask image\n            mask_file = os.path.join(mask_folder, f\"{file_name}.png\")\n            \n            # Check if the mask image file exists\n            if not os.path.isfile(mask_file):\n                #print(f\"Mask image not found for: {clinical_file}\")\n                continue\n            \n            # Read the mask image\n            mask_image = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n            mask_image = cv2.resize(mask_image, (224, 224))\n            mask_image = mask_image / 255.0\n            label = 0  # Initialize as 0 (normal)\n            if \"normal\" not in disease_description:\n                label = 1  # Set to 1 if disease is mentioned\n                \n            data.append(mask_image)\n            labels.append(label)\n        \n\ndata = np.array(data)\nlabels = np.array(labels)\n\n# Shuffle the data and labels\nindices = np.arange(len(data))\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T04:54:56.724910Z","iopub.execute_input":"2024-11-17T04:54:56.725207Z","iopub.status.idle":"2024-11-17T04:55:40.006953Z","shell.execute_reply.started":"2024-11-17T04:54:56.725180Z","shell.execute_reply":"2024-11-17T04:55:40.006140Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"print(len(data),len(labels))","metadata":{"execution":{"iopub.status.busy":"2024-11-17T04:55:40.008686Z","iopub.execute_input":"2024-11-17T04:55:40.009162Z","iopub.status.idle":"2024-11-17T04:55:40.014840Z","shell.execute_reply.started":"2024-11-17T04:55:40.009127Z","shell.execute_reply":"2024-11-17T04:55:40.013948Z"},"trusted":true},"outputs":[{"name":"stdout","text":"704 704\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training (80%), validation (10%), and test (10%) sets\n# You can adjust the test_size and random_state parameters as needed\nX_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.20, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n\n# Print the sizes of each set to verify the split\nprint(\"Training set size:\", len(X_train))\nprint(\"Validation set size:\", len(X_val))\nprint(\"Test set size:\", len(X_test))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T04:55:40.015917Z","iopub.execute_input":"2024-11-17T04:55:40.016185Z","iopub.status.idle":"2024-11-17T04:55:40.600359Z","shell.execute_reply.started":"2024-11-17T04:55:40.016162Z","shell.execute_reply":"2024-11-17T04:55:40.599296Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Training set size: 563\nValidation set size: 70\nTest set size: 71\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(X_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T04:55:40.602414Z","iopub.execute_input":"2024-11-17T04:55:40.602784Z","iopub.status.idle":"2024-11-17T04:55:40.607543Z","shell.execute_reply.started":"2024-11-17T04:55:40.602758Z","shell.execute_reply":"2024-11-17T04:55:40.606735Z"}},"outputs":[{"name":"stdout","text":"(563, 224, 224)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential()\n\n# Convolutional Layer 1\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))\nmodel.add(MaxPooling2D((2, 2)))\n\n# Convolutional Layer 2\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\n# Convolutional Layer 3\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n# Flatten Layer\nmodel.add(Flatten())\n\n# Fully Connected Layer 1\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))  # Dropout for regularization\n\n# Fully Connected Layer 2\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\n\n# Output Layer\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T04:55:40.608606Z","iopub.execute_input":"2024-11-17T04:55:40.608845Z","iopub.status.idle":"2024-11-17T04:55:49.600997Z","shell.execute_reply.started":"2024-11-17T04:55:40.608824Z","shell.execute_reply":"2024-11-17T04:55:49.599833Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 222, 222, 32)      320       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n 2D)                                                             \n                                                                 \n conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n 2D)                                                             \n                                                                 \n conv2d_3 (Conv2D)           (None, 24, 24, 256)       295168    \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 12, 12, 256)      0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 36864)             0         \n                                                                 \n dense (Dense)               (None, 64)                2359360   \n                                                                 \n dropout (Dropout)           (None, 64)                0         \n                                                                 \n dense_1 (Dense)             (None, 128)               8320      \n                                                                 \n dropout_1 (Dropout)         (None, 128)               0         \n                                                                 \n dense_2 (Dense)             (None, 1)                 129       \n                                                                 \n=================================================================\nTotal params: 2,755,649\nTrainable params: 2,755,649\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\n# Define a ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(\"best_weights.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#datagen.fit(X_train)  # Assuming you have a training dataset X_train\n\n# Train the model with the callback\nhistory = model.fit(\n    X_train,\n    y_train,\n    epochs=100,\n    batch_size=16,\n    validation_data=(X_val, y_val),\n    callbacks=[checkpoint]  # Add the checkpoint callback\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T04:55:49.602231Z","iopub.execute_input":"2024-11-17T04:55:49.602529Z","iopub.status.idle":"2024-11-17T04:56:57.436024Z","shell.execute_reply.started":"2024-11-17T04:55:49.602495Z","shell.execute_reply":"2024-11-17T04:56:57.435187Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/100\n36/36 [==============================] - ETA: 0s - loss: 0.7100 - accuracy: 0.5044\nEpoch 1: val_accuracy improved from -inf to 0.61429, saving model to best_weights.h5\n36/36 [==============================] - 7s 34ms/step - loss: 0.7100 - accuracy: 0.5044 - val_loss: 0.6494 - val_accuracy: 0.6143\nEpoch 2/100\n34/36 [===========================>..] - ETA: 0s - loss: 0.6695 - accuracy: 0.5974\nEpoch 2: val_accuracy improved from 0.61429 to 0.62857, saving model to best_weights.h5\n36/36 [==============================] - 1s 20ms/step - loss: 0.6677 - accuracy: 0.5986 - val_loss: 0.7383 - val_accuracy: 0.6286\nEpoch 3/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.6580 - accuracy: 0.6155\nEpoch 3: val_accuracy improved from 0.62857 to 0.64286, saving model to best_weights.h5\n36/36 [==============================] - 1s 20ms/step - loss: 0.7177 - accuracy: 0.6181 - val_loss: 0.6710 - val_accuracy: 0.6429\nEpoch 4/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5998 - accuracy: 0.6780\nEpoch 4: val_accuracy did not improve from 0.64286\n36/36 [==============================] - 1s 17ms/step - loss: 1.2999 - accuracy: 0.6750 - val_loss: 0.6895 - val_accuracy: 0.6286\nEpoch 5/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.6545 - accuracy: 0.6288\nEpoch 5: val_accuracy improved from 0.64286 to 0.67143, saving model to best_weights.h5\n36/36 [==============================] - 1s 20ms/step - loss: 0.6489 - accuracy: 0.6359 - val_loss: 0.6441 - val_accuracy: 0.6714\nEpoch 6/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.6185 - accuracy: 0.6761\nEpoch 6: val_accuracy did not improve from 0.67143\n36/36 [==============================] - 1s 17ms/step - loss: 0.9317 - accuracy: 0.6803 - val_loss: 0.6666 - val_accuracy: 0.6714\nEpoch 7/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5732 - accuracy: 0.7027\nEpoch 7: val_accuracy did not improve from 0.67143\n36/36 [==============================] - 1s 17ms/step - loss: 2.8638 - accuracy: 0.6945 - val_loss: 0.6995 - val_accuracy: 0.6429\nEpoch 8/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5850 - accuracy: 0.6837\nEpoch 8: val_accuracy improved from 0.67143 to 0.71429, saving model to best_weights.h5\n36/36 [==============================] - 1s 20ms/step - loss: 0.6666 - accuracy: 0.6803 - val_loss: 0.7550 - val_accuracy: 0.7143\nEpoch 9/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5810 - accuracy: 0.6799\nEpoch 9: val_accuracy did not improve from 0.71429\n36/36 [==============================] - 1s 17ms/step - loss: 2.2998 - accuracy: 0.6821 - val_loss: 1.1511 - val_accuracy: 0.6571\nEpoch 10/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5693 - accuracy: 0.6989\nEpoch 10: val_accuracy did not improve from 0.71429\n36/36 [==============================] - 1s 17ms/step - loss: 0.5674 - accuracy: 0.7034 - val_loss: 2.0928 - val_accuracy: 0.6429\nEpoch 11/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5394 - accuracy: 0.7311\nEpoch 11: val_accuracy did not improve from 0.71429\n36/36 [==============================] - 1s 17ms/step - loss: 0.5572 - accuracy: 0.7371 - val_loss: 1.6851 - val_accuracy: 0.6286\nEpoch 12/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5294 - accuracy: 0.7367\nEpoch 12: val_accuracy did not improve from 0.71429\n36/36 [==============================] - 1s 17ms/step - loss: 0.7038 - accuracy: 0.7318 - val_loss: 7.2446 - val_accuracy: 0.6286\nEpoch 13/100\n34/36 [===========================>..] - ETA: 0s - loss: 0.5696 - accuracy: 0.6875\nEpoch 13: val_accuracy did not improve from 0.71429\n36/36 [==============================] - 1s 18ms/step - loss: 2.2095 - accuracy: 0.6856 - val_loss: 14.5363 - val_accuracy: 0.6143\nEpoch 14/100\n36/36 [==============================] - ETA: 0s - loss: 4.4815 - accuracy: 0.7247\nEpoch 14: val_accuracy improved from 0.71429 to 0.75714, saving model to best_weights.h5\n36/36 [==============================] - 1s 20ms/step - loss: 4.4815 - accuracy: 0.7247 - val_loss: 0.5971 - val_accuracy: 0.7571\nEpoch 15/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5317 - accuracy: 0.7216\nEpoch 15: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.5283 - accuracy: 0.7265 - val_loss: 0.6236 - val_accuracy: 0.7143\nEpoch 16/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4902 - accuracy: 0.7557\nEpoch 16: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 5.8456 - accuracy: 0.7567 - val_loss: 0.6433 - val_accuracy: 0.7429\nEpoch 17/100\n36/36 [==============================] - ETA: 0s - loss: 3.6233 - accuracy: 0.7620\nEpoch 17: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 3.6233 - accuracy: 0.7620 - val_loss: 0.6596 - val_accuracy: 0.6857\nEpoch 18/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4030 - accuracy: 0.8201\nEpoch 18: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 8.7477 - accuracy: 0.8206 - val_loss: 0.7628 - val_accuracy: 0.7000\nEpoch 19/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4457 - accuracy: 0.7917\nEpoch 19: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.8081 - accuracy: 0.7886 - val_loss: 0.7858 - val_accuracy: 0.6000\nEpoch 20/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4217 - accuracy: 0.8030\nEpoch 20: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 1.5726 - accuracy: 0.8099 - val_loss: 0.8289 - val_accuracy: 0.6143\nEpoch 21/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4258 - accuracy: 0.7955\nEpoch 21: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 6.3990 - accuracy: 0.7957 - val_loss: 0.8064 - val_accuracy: 0.6714\nEpoch 22/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4048 - accuracy: 0.8125\nEpoch 22: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 8.3053 - accuracy: 0.8117 - val_loss: 0.9082 - val_accuracy: 0.6286\nEpoch 23/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3849 - accuracy: 0.8295\nEpoch 23: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 1.4935 - accuracy: 0.8242 - val_loss: 0.7396 - val_accuracy: 0.6857\nEpoch 24/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3996 - accuracy: 0.7973\nEpoch 24: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 1.1702 - accuracy: 0.8011 - val_loss: 0.9267 - val_accuracy: 0.6857\nEpoch 25/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3678 - accuracy: 0.8163\nEpoch 25: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3627 - accuracy: 0.8188 - val_loss: 1.5541 - val_accuracy: 0.7000\nEpoch 26/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3379 - accuracy: 0.8333\nEpoch 26: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 2.0314 - accuracy: 0.8348 - val_loss: 0.8641 - val_accuracy: 0.6429\nEpoch 27/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3644 - accuracy: 0.8258\nEpoch 27: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 1.0769 - accuracy: 0.8188 - val_loss: 0.9098 - val_accuracy: 0.7000\nEpoch 28/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3299 - accuracy: 0.8428\nEpoch 28: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 12.0383 - accuracy: 0.8419 - val_loss: 1.2885 - val_accuracy: 0.7143\nEpoch 29/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4597 - accuracy: 0.8258\nEpoch 29: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.4500 - accuracy: 0.8259 - val_loss: 2.5335 - val_accuracy: 0.6571\nEpoch 30/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3381 - accuracy: 0.8390\nEpoch 30: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 2.0982 - accuracy: 0.8419 - val_loss: 2.3984 - val_accuracy: 0.6571\nEpoch 31/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3232 - accuracy: 0.8485\nEpoch 31: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 17.9571 - accuracy: 0.8401 - val_loss: 1.2815 - val_accuracy: 0.6286\nEpoch 32/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.6106 - accuracy: 0.7765\nEpoch 32: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 2.9094 - accuracy: 0.7709 - val_loss: 11.0892 - val_accuracy: 0.6857\nEpoch 33/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5690 - accuracy: 0.7765\nEpoch 33: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 1.3120 - accuracy: 0.7709 - val_loss: 7.8087 - val_accuracy: 0.6286\nEpoch 34/100\n36/36 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.7602\nEpoch 34: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.4844 - accuracy: 0.7602 - val_loss: 19.4429 - val_accuracy: 0.6286\nEpoch 35/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4012 - accuracy: 0.8125\nEpoch 35: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.5162 - accuracy: 0.8153 - val_loss: 41.5021 - val_accuracy: 0.6571\nEpoch 36/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3994 - accuracy: 0.8144\nEpoch 36: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 7.5997 - accuracy: 0.8117 - val_loss: 64.0924 - val_accuracy: 0.6429\nEpoch 37/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.7758 - accuracy: 0.7367\nEpoch 37: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 17.7445 - accuracy: 0.7389 - val_loss: 0.8430 - val_accuracy: 0.6143\nEpoch 38/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4913 - accuracy: 0.7254\nEpoch 38: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 3.2434 - accuracy: 0.7371 - val_loss: 0.9968 - val_accuracy: 0.6000\nEpoch 39/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5144 - accuracy: 0.7386\nEpoch 39: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 31.9010 - accuracy: 0.7300 - val_loss: 1.2006 - val_accuracy: 0.6429\nEpoch 40/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4530 - accuracy: 0.7727\nEpoch 40: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.6125 - accuracy: 0.7709 - val_loss: 1.1326 - val_accuracy: 0.6857\nEpoch 41/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4380 - accuracy: 0.7519\nEpoch 41: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 43.0313 - accuracy: 0.7425 - val_loss: 1.4214 - val_accuracy: 0.6143\nEpoch 42/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.6573 - accuracy: 0.7159\nEpoch 42: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 1.2498 - accuracy: 0.7158 - val_loss: 1.4068 - val_accuracy: 0.5857\nEpoch 43/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.6207 - accuracy: 0.6761\nEpoch 43: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.6105 - accuracy: 0.6785 - val_loss: 1.1700 - val_accuracy: 0.6143\nEpoch 44/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.5368 - accuracy: 0.7140\nEpoch 44: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 4.7312 - accuracy: 0.7194 - val_loss: 1.0433 - val_accuracy: 0.5429\nEpoch 45/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4636 - accuracy: 0.7216\nEpoch 45: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.6046 - accuracy: 0.7211 - val_loss: 1.1687 - val_accuracy: 0.7571\nEpoch 46/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4653 - accuracy: 0.6913\nEpoch 46: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 3.4579 - accuracy: 0.6892 - val_loss: 1.4779 - val_accuracy: 0.7286\nEpoch 47/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3920 - accuracy: 0.7008\nEpoch 47: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3937 - accuracy: 0.6998 - val_loss: 1.2754 - val_accuracy: 0.6429\nEpoch 48/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4341 - accuracy: 0.7633\nEpoch 48: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.4350 - accuracy: 0.7620 - val_loss: 1.2750 - val_accuracy: 0.6286\nEpoch 49/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3938 - accuracy: 0.7784\nEpoch 49: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3855 - accuracy: 0.7833 - val_loss: 1.3047 - val_accuracy: 0.6714\nEpoch 50/100\n36/36 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.7993\nEpoch 50: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3689 - accuracy: 0.7993 - val_loss: 1.3255 - val_accuracy: 0.6857\nEpoch 51/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3644 - accuracy: 0.7879\nEpoch 51: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3648 - accuracy: 0.7851 - val_loss: 1.3332 - val_accuracy: 0.6857\nEpoch 52/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3233 - accuracy: 0.8295\nEpoch 52: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3202 - accuracy: 0.8242 - val_loss: 1.5175 - val_accuracy: 0.6714\nEpoch 53/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3288 - accuracy: 0.8011\nEpoch 53: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3322 - accuracy: 0.7975 - val_loss: 1.2958 - val_accuracy: 0.6857\nEpoch 54/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3494 - accuracy: 0.8030\nEpoch 54: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3411 - accuracy: 0.8082 - val_loss: 1.5253 - val_accuracy: 0.6429\nEpoch 55/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3175 - accuracy: 0.8011\nEpoch 55: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3160 - accuracy: 0.8082 - val_loss: 1.5438 - val_accuracy: 0.6857\nEpoch 56/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2776 - accuracy: 0.8504\nEpoch 56: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2792 - accuracy: 0.8455 - val_loss: 1.4058 - val_accuracy: 0.6571\nEpoch 57/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3175 - accuracy: 0.8182\nEpoch 57: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3205 - accuracy: 0.8135 - val_loss: 1.4611 - val_accuracy: 0.6286\nEpoch 58/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2645 - accuracy: 0.8295\nEpoch 58: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2627 - accuracy: 0.8277 - val_loss: 1.6225 - val_accuracy: 0.6429\nEpoch 59/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2507 - accuracy: 0.8428\nEpoch 59: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2525 - accuracy: 0.8419 - val_loss: 1.5820 - val_accuracy: 0.6714\nEpoch 60/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2632 - accuracy: 0.8352\nEpoch 60: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2678 - accuracy: 0.8313 - val_loss: 1.7473 - val_accuracy: 0.6714\nEpoch 61/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2504 - accuracy: 0.8466\nEpoch 61: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.4374 - accuracy: 0.8419 - val_loss: 1.9587 - val_accuracy: 0.6571\nEpoch 62/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3912 - accuracy: 0.7822\nEpoch 62: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3803 - accuracy: 0.7886 - val_loss: 2.1670 - val_accuracy: 0.6429\nEpoch 63/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.4090 - accuracy: 0.7822\nEpoch 63: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.4104 - accuracy: 0.7726 - val_loss: 1.8806 - val_accuracy: 0.6429\nEpoch 64/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.3286 - accuracy: 0.8201\nEpoch 64: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.3286 - accuracy: 0.8135 - val_loss: 1.9450 - val_accuracy: 0.6714\nEpoch 65/100\n35/36 [============================>.] - ETA: 0s - loss: 0.2739 - accuracy: 0.8482\nEpoch 65: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2762 - accuracy: 0.8455 - val_loss: 2.1533 - val_accuracy: 0.6714\nEpoch 66/100\n35/36 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.8625\nEpoch 66: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 18ms/step - loss: 0.2512 - accuracy: 0.8632 - val_loss: 1.9352 - val_accuracy: 0.6714\nEpoch 67/100\n35/36 [============================>.] - ETA: 0s - loss: 0.2494 - accuracy: 0.8518\nEpoch 67: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2518 - accuracy: 0.8490 - val_loss: 1.9914 - val_accuracy: 0.6571\nEpoch 68/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2125 - accuracy: 0.8617\nEpoch 68: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2111 - accuracy: 0.8615 - val_loss: 2.1091 - val_accuracy: 0.6714\nEpoch 69/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2242 - accuracy: 0.8883\nEpoch 69: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2326 - accuracy: 0.8845 - val_loss: 2.1132 - val_accuracy: 0.6714\nEpoch 70/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2148 - accuracy: 0.8731\nEpoch 70: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2151 - accuracy: 0.8686 - val_loss: 2.1703 - val_accuracy: 0.6857\nEpoch 71/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2073 - accuracy: 0.8864\nEpoch 71: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2181 - accuracy: 0.8828 - val_loss: 2.1294 - val_accuracy: 0.6857\nEpoch 72/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2721 - accuracy: 0.8409\nEpoch 72: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2748 - accuracy: 0.8348 - val_loss: 2.0846 - val_accuracy: 0.7000\nEpoch 73/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2533 - accuracy: 0.8371\nEpoch 73: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2517 - accuracy: 0.8384 - val_loss: 2.0594 - val_accuracy: 0.6857\nEpoch 74/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2172 - accuracy: 0.8712\nEpoch 74: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2223 - accuracy: 0.8686 - val_loss: 2.0710 - val_accuracy: 0.7000\nEpoch 75/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2290 - accuracy: 0.8617\nEpoch 75: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2303 - accuracy: 0.8668 - val_loss: 2.0667 - val_accuracy: 0.7143\nEpoch 76/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2222 - accuracy: 0.8352\nEpoch 76: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2274 - accuracy: 0.8330 - val_loss: 2.2238 - val_accuracy: 0.7143\nEpoch 77/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2065 - accuracy: 0.8864\nEpoch 77: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2066 - accuracy: 0.8845 - val_loss: 2.4015 - val_accuracy: 0.6714\nEpoch 78/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2202 - accuracy: 0.8580\nEpoch 78: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 16ms/step - loss: 0.2225 - accuracy: 0.8579 - val_loss: 2.1793 - val_accuracy: 0.7000\nEpoch 79/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1763 - accuracy: 0.8864\nEpoch 79: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1808 - accuracy: 0.8845 - val_loss: 2.1032 - val_accuracy: 0.7286\nEpoch 80/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2565 - accuracy: 0.8504\nEpoch 80: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2549 - accuracy: 0.8561 - val_loss: 2.1939 - val_accuracy: 0.6857\nEpoch 81/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2314 - accuracy: 0.8826\nEpoch 81: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2325 - accuracy: 0.8845 - val_loss: 2.0434 - val_accuracy: 0.6714\nEpoch 82/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1920 - accuracy: 0.8920\nEpoch 82: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1932 - accuracy: 0.8881 - val_loss: 2.2407 - val_accuracy: 0.7143\nEpoch 83/100\n36/36 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.8792\nEpoch 83: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2030 - accuracy: 0.8792 - val_loss: 2.1736 - val_accuracy: 0.7286\nEpoch 84/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1743 - accuracy: 0.8939\nEpoch 84: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1780 - accuracy: 0.8881 - val_loss: 2.3309 - val_accuracy: 0.6714\nEpoch 85/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1945 - accuracy: 0.8769\nEpoch 85: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 16ms/step - loss: 0.1964 - accuracy: 0.8757 - val_loss: 2.3241 - val_accuracy: 0.7000\nEpoch 86/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1803 - accuracy: 0.8864\nEpoch 86: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1816 - accuracy: 0.8828 - val_loss: 2.6750 - val_accuracy: 0.6857\nEpoch 87/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1931 - accuracy: 0.8920\nEpoch 87: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2011 - accuracy: 0.8863 - val_loss: 2.6862 - val_accuracy: 0.7000\nEpoch 88/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1864 - accuracy: 0.9091\nEpoch 88: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2010 - accuracy: 0.9023 - val_loss: 2.5393 - val_accuracy: 0.7000\nEpoch 89/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1807 - accuracy: 0.8883\nEpoch 89: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1869 - accuracy: 0.8863 - val_loss: 2.6127 - val_accuracy: 0.6571\nEpoch 90/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1811 - accuracy: 0.8883\nEpoch 90: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1873 - accuracy: 0.8828 - val_loss: 2.7370 - val_accuracy: 0.7286\nEpoch 91/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1930 - accuracy: 0.8826\nEpoch 91: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1967 - accuracy: 0.8774 - val_loss: 2.5056 - val_accuracy: 0.6857\nEpoch 92/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2142 - accuracy: 0.8864\nEpoch 92: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2182 - accuracy: 0.8828 - val_loss: 2.1131 - val_accuracy: 0.6857\nEpoch 93/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2127 - accuracy: 0.8655\nEpoch 93: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2088 - accuracy: 0.8686 - val_loss: 2.0845 - val_accuracy: 0.6714\nEpoch 94/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.2006 - accuracy: 0.8788\nEpoch 94: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.2009 - accuracy: 0.8792 - val_loss: 2.4828 - val_accuracy: 0.6714\nEpoch 95/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1754 - accuracy: 0.8996\nEpoch 95: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1794 - accuracy: 0.8988 - val_loss: 2.3039 - val_accuracy: 0.7000\nEpoch 96/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1917 - accuracy: 0.8864\nEpoch 96: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1975 - accuracy: 0.8828 - val_loss: 2.4741 - val_accuracy: 0.6429\nEpoch 97/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1852 - accuracy: 0.9129\nEpoch 97: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1864 - accuracy: 0.9147 - val_loss: 2.5209 - val_accuracy: 0.6857\nEpoch 98/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1765 - accuracy: 0.8939\nEpoch 98: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1763 - accuracy: 0.8952 - val_loss: 2.3231 - val_accuracy: 0.6714\nEpoch 99/100\n33/36 [==========================>...] - ETA: 0s - loss: 0.1769 - accuracy: 0.8845\nEpoch 99: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1784 - accuracy: 0.8845 - val_loss: 2.8255 - val_accuracy: 0.6714\nEpoch 100/100\n36/36 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.9023\nEpoch 100: val_accuracy did not improve from 0.75714\n36/36 [==============================] - 1s 17ms/step - loss: 0.1724 - accuracy: 0.9023 - val_loss: 2.7904 - val_accuracy: 0.6714\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Convert predicted probabilities to binary predictions using a threshold of 0.5\nthreshold = 0\naccuracy=0\nthres=0\ny_pred = model.predict(X_test)\n# Load the best weights\nmodel.load_weights(\"best_weights.h5\")\nwhile threshold<=10:\n    y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n\n    # Calculate the test accuracy\n    test_accuracy = accuracy_score(y_test, y_pred_binary)\n    if test_accuracy>accuracy:\n        thres=threshold\n        accuracy=test_accuracy\n    threshold=threshold+0.10\n\nprint(thres,accuracy)\nthreshold=thres\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-17T04:56:57.437539Z","iopub.execute_input":"2024-11-17T04:56:57.438040Z","iopub.status.idle":"2024-11-17T04:56:58.265172Z","shell.execute_reply.started":"2024-11-17T04:56:57.438003Z","shell.execute_reply":"2024-11-17T04:56:58.264236Z"},"trusted":true},"outputs":[{"name":"stdout","text":"3/3 [==============================] - 0s 49ms/step\n0.7 0.676056338028169\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n# Threshold the predicted probabilities and calculate accuracy\ny_pred_binary = np.where(y_pred >= threshold, 1, 0)\ntest_accuracy = accuracy_score(y_test, y_pred_binary)\n\nprint(\"Test Accuracy with Best Weights:\", test_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T04:56:58.266380Z","iopub.execute_input":"2024-11-17T04:56:58.266680Z","iopub.status.idle":"2024-11-17T04:56:58.272541Z","shell.execute_reply.started":"2024-11-17T04:56:58.266650Z","shell.execute_reply":"2024-11-17T04:56:58.271646Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test Accuracy with Best Weights: 0.676056338028169\n","output_type":"stream"}],"execution_count":8}]}